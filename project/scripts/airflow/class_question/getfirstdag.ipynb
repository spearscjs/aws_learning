{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nimport sys\\nimport os\\nimport datetime\\nimport pandas\\nfrom scripts.class_question import class_question3 as cq\\nfrom utils import s3\\n\\nrecord_num_request = 50000\\ntarget_date = datetime.datetime(2023, 2, 1)\\ndiff = datetime.timedelta(days=1)\\n\\nbucket = \\'quintrix-spearscjs\\'\\n\\nfilepath = f\\'data/cards_ingest/order_data/\\'\\nif(not os.path.exists(filepath)):\\n    os.makedirs(filepath)\\n\\nfor i in range(10):\\n    filename = f\\'order_data_{target_date.strftime(\"%Y%m%d\")}.csv\\'\\n    print(filepath + filename)\\n    df = cq.generate_dummy_info(record_num_request, target_date, target_date)\\n    df.to_csv(filepath + filename, index= False)\\n    target_date += diff\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "1. Create a python function (Script) to generate data : Sample data and store in a CSV file in you laptop. [50000 records]\n",
    "The file name: order_data_20230201.csv\n",
    "\n",
    "\n",
    "orderid,brand_name,product_name,sales_ammount,sales_date\n",
    "orderid: Unique id with 7 digit number in sequence[Pandas function random number]\n",
    "brand_name:['Apple','Samsung','Nokia']\n",
    "product_name is Key value pair\n",
    "product_name:{'Apple':['iphon11','iphone12','iphone13','iphoneSE','IpadMax','IpadMini','laptop256','Macbook512'],\n",
    "'Samsung':['galaxy10','galaxy11','galaxy12','galaxy13','watch320','watch340'],\n",
    "'Nokia':['Nk320',''Nk400',''Nk500']\n",
    "sales_ammount : random ammout with (5,2) decimal.\n",
    "sales_datetime : 2023-02-01 to 2023-02-20\n",
    "\n",
    "Finally data should be like this\n",
    "1002346,Apple,iphon11,450,2023-02-01 10:30\n",
    "1002246,Apple,iphon11,460,2023-02-01 11:20\n",
    "1002546,Apple,iphoneSE,350,2023-02-01 12:20\n",
    "\n",
    "Generate 10 files. Copy them into s3 into one bucket. [[ lets say bucket1/folder1 ]]\n",
    "\n",
    "'''\n",
    "# see class question 3\n",
    "\n",
    "''' \n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas\n",
    "from scripts.class_question import class_question3 as cq\n",
    "from utils import s3\n",
    "\n",
    "record_num_request = 50000\n",
    "target_date = datetime.datetime(2023, 2, 1)\n",
    "diff = datetime.timedelta(days=1)\n",
    "\n",
    "bucket = 'quintrix-spearscjs'\n",
    "\n",
    "filepath = f'data/cards_ingest/order_data/'\n",
    "if(not os.path.exists(filepath)):\n",
    "    os.makedirs(filepath)\n",
    "\n",
    "for i in range(10):\n",
    "    filename = f'order_data_{target_date.strftime(\"%Y%m%d\")}.csv'\n",
    "    print(filepath + filename)\n",
    "    df = cq.generate_dummy_info(record_num_request, target_date, target_date)\n",
    "    df.to_csv(filepath + filename, index= False)\n",
    "    target_date += diff\n",
    "''' \n",
    "# uploaded to s3 using CLI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dags/ingest_order_data.py\n",
    "\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name='dev_acct')\n",
    "client = session.client('s3')\n",
    "s3 = session.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' \n",
    "1. Create a dag to have 4 task\n",
    "\n",
    "\n",
    "Task 1. sensor\n",
    "use date parameter from dag.\n",
    "date=20230201\n",
    "1. Check file exists in s3 bucket1/folder1/order_data_{date}.csv\n",
    "''' \n",
    "\n",
    "''' \n",
    "Task 2:\n",
    "2. Copy the file to another folder with\n",
    "bucket1/folder2/2023-02-01/order_data_20230201.csv\n",
    "bucket1/folder2/2023-02-02/order_data_20230202.csv\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "Task3:\n",
    "3. Run the crawler to add the partition as dataset_date\n",
    "\n",
    "Task4 .\n",
    "Run a glue job (spark job)\n",
    "get the total ammount by brand_name,product_name,dataset_date and load into file. Makse sure you have dynamic partition by brand_name\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2107450931.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_16802/2107450931.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(f's3://quintrix-spearscjs/data/cards_ingest/order_data/dataset_date={date.today()}/order_data_{'a'}.csv')\u001b[0m\n\u001b[0m                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "print(f's3://quintrix-spearscjs/data/cards_ingest/order_data/dataset_date={date.today()}/order_data_.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
