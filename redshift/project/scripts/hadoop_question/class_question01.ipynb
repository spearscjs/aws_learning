{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import db\n",
    "from utils import s3\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 41\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mcreate table if not exists cust_tran_fact\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mtblproperties (\"skip.header.line.count\"=\"1\") ;\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# generate dummy data\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m start_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39;49mdatetime(\u001b[39m2022\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     42\u001b[0m num_days \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[0;32m     43\u001b[0m num_records \u001b[39m=\u001b[39m \u001b[39m5000\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" \n",
    "1.Create table :tran_fact\n",
    "# 2. Create static partition as dataset_date as varchar(10). Make sure tran_date = dataset_date-1\n",
    "# PROBLEM: parquet requires column names and meta data\n",
    "\n",
    "\n",
    "tran_id int, cust_id varchar(20),tran_date date,tran_ammount decimal(10,2), tran_type varchar(1)\n",
    "\n",
    "tran_id : unique id of 6 character\n",
    "cust_id : CA+ 4 integer\n",
    "tran_date: is constant for one file\n",
    "tran_ammount: number havin decimal(10,2)\n",
    "tran_type :[C/D]\n",
    "sate_cd :varchar(2)\n",
    "\n",
    "\n",
    "102020,CA1001,2022-02-01,1200,C,CA\n",
    "102021,CA1002,2022-02-01,700,C,NY\n",
    "102022,CA1003,2022-02-01,500,C,NJ\n",
    "102023,CA1004,2022-02-02,900,C,VA\n",
    "102020,CA1001,2022-02-02,200,D,CA\n",
    "&/\n",
    "\n",
    "*/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "create table if not exists cust_tran_fact\n",
    "(\n",
    "    tran_id varchar(10) , \n",
    "    cust_id varchar(20) ,\n",
    "    tran_ammount decimal(10,2), \n",
    "    tran_type varchar(1) , \n",
    "    tran_stat_cd varchar(2) ,\n",
    "    tran_date date\n",
    ")\n",
    "partitioned by (load_date varchar(10))\n",
    "row format delimited fields terminated by ','\n",
    "location \"s3://quintrix-spearscjs/data/src_customer/cust_tran_fact/\"\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# generate dummy data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 8639 records for 2023-01-01\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-01.csv\n",
      "Generating 8209 records for 2023-01-02\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-02.csv\n",
      "Generating 2653 records for 2023-01-03\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-03.csv\n",
      "Generating 6999 records for 2023-01-04\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-04.csv\n",
      "Generating 6083 records for 2023-01-05\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-05.csv\n",
      "Generating 5448 records for 2023-01-06\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-06.csv\n",
      "Generating 6700 records for 2023-01-07\n",
      "data/src_customer/cust_tran_fact/daily/cust_tran_fact_2023-01-07.csv\n",
      "Data generated for 7 days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "start_date = datetime(2023, 1, 1)\n",
    "number_of_days = 7\n",
    "record_count_min = 1000\n",
    "record_count_max = 10000\n",
    "\n",
    "tran_types = ['C', 'D']\n",
    "state_cds = ['CA', 'AZ', 'NJ', 'AL', 'AK', 'CO', 'KY', 'WV']\n",
    "\n",
    "\n",
    "def generate_dummy_info(record_count: int, date: datetime, start_id = 0):\n",
    "    print(f'Generating {record_count} records for {date.strftime(\"%Y-%m-%d\")}')\n",
    "    ran_data = []\n",
    "    for i in range(1, record_count+1):\n",
    "        tran_id = f'{start_id + i:06}'\n",
    "        cust_id = f'CA{random.randint(0,9999):04}'\n",
    "        tran_ammount = round(random.uniform(100.00, 99999999.99),2)\n",
    "        tran_type = random.choice(tran_types)\n",
    "        stat_cd = random.choice(state_cds)\n",
    "        tran_date = date.strftime(\"%Y-%m-%d\")\n",
    "        ran_data.append((tran_id, cust_id, tran_ammount, tran_type, stat_cd, tran_date))\n",
    "\n",
    "    df = pd.DataFrame(ran_data, columns=['tran_id', 'cust_id', 'tran_ammount', 'tran_type', 'tran_stat_cd', 'tran_date'])\n",
    "    filename = f'data/src_customer/cust_tran_fact/daily/cust_tran_fact_{date.strftime(\"%Y-%m-%d\")}.csv'\n",
    "    # df.to_parquet(filename, engine=\"fastparquet\", )\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "def generate_for_days(min_record_num: int, max_record_num: int, start_date: datetime, days: int):\n",
    "    cur_date = start_date\n",
    "    filenames = []\n",
    "    count = 0\n",
    "    for i in range(days):\n",
    "        num_records = random.randint(min_record_num, max_record_num)\n",
    "        filename = generate_dummy_info(num_records, cur_date, count)\n",
    "        print(filename)\n",
    "        filenames.append((filename, cur_date.strftime(\"%Y-%m-%d\")))\n",
    "        cur_date += timedelta(days=1)\n",
    "        count += num_records\n",
    "    print(f'Data generated for {days} days')\n",
    "    return filenames\n",
    "\n",
    "filenames = generate_for_days(record_count_min, record_count_max, start_date, number_of_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data to s3\n",
    "for f in filenames:\n",
    "    filename = f[0]\n",
    "    name = f[0].split('/')[4]\n",
    "    # add upload date for s3 folder names / hive partitions (tran_date plus one)\n",
    "    date = list(f[1])\n",
    "    date[9] = str((int(date[9]) + 1 ) % 10)\n",
    "    date = \"\".join(date)\n",
    "    s3.upload_file(filename, 'quintrix-spearscjs', f'data/src_customer/cust_tran_fact/load_date={date}/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add 7 partitions dataset_date\n",
    "\n",
    "\"\"\" \n",
    "set hivevar:src_schema=src_customer;\n",
    "use ${hivevar:src_schema};\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-02');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-03');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-04');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-05');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-06');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-07');\n",
    "alter table cust_tran_fact add partition (load_date='2023-01-08');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\" \n",
    "/*\n",
    "Dataquality check:\n",
    "1. create a table as table_states:\n",
    "cols:\n",
    "database_name varchar(20),\n",
    "table_name varchar(50),\n",
    "partition_key varchar(30),\n",
    "rec_count int(10),\n",
    "load_date date,\n",
    "execution_key varchar(100)  >>> Partition col\n",
    "\n",
    "execution_key is (database_name + \"-\"+table_name+\"-\"+partition_key\n",
    "\n",
    "\n",
    "2. After each load into tran_fact run the query to load data into table_states\n",
    "query is : get the count from tran_fact an load into table_states\n",
    "\n",
    "*/\n",
    "\"\"\" \n",
    "\"\"\" \n",
    "\n",
    "create table if not exists table_states (\n",
    "    database_name varchar(20),\n",
    "    table_name varchar(50),\n",
    "    partition_key varchar(30),\n",
    "    rec_count int,\n",
    "    load_date date\n",
    ")\n",
    "partitioned by (execution_key varchar(100))\n",
    "stored as parquet\n",
    "location \"s3://quintrix-spearscjs/data/src_customer/cust_tran_fact/\";\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "insert overwrite table_states( \n",
    " database_name varchar(20),\n",
    " table_name varchar(50),\n",
    " partition_key varchar(30),\n",
    " rec_count int,\n",
    " load_date date\n",
    ")\n",
    "select 'src_customer' database_name, \n",
    " 'cust_tran_fact' table_name, \n",
    " 'load_date' partition_key, \n",
    " count(1) rec_count,\n",
    " load_date load_date\n",
    "\n",
    "from cust_tran_fact \n",
    "GROUP BY load_date;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "-- 1. Total unique customer per day.\n",
    "SELECT tran_date, COUNT(DISTINCT cust_id) unique_customers \n",
    "FROM cust_tran_fact \n",
    "GROUP BY tran_date;\n",
    "\n",
    "-- 2. Total number of unique customer till date (BROKEN FOR EMR)\n",
    "/*\n",
    "rank -- partition by cust order date\n",
    "\n",
    "\n",
    "*/\n",
    "-- using sum\n",
    "WITH ranks AS (\n",
    "    SELECT DISTINCT cust_id, tran_date, RANK() OVER(PARTITION BY cust_id ORDER BY tran_date)\n",
    "    FROM cust_tran_fact\n",
    ")\n",
    "SELECT DISTINCT tran_date, \n",
    "    SUM(CASE WHEN rank = 1 THEN 1 ELSE 0 END) OVER(ORDER BY tran_date) total_unique_cust \n",
    "FROM ranks\n",
    " ORDER BY tran_date;\n",
    "\n",
    "\n",
    "-- using nested select\n",
    "SELECT DISTINCT tran_date,\n",
    "       (SELECT COUNT(DISTINCT cust_id) FROM cust_tran_fact  WHERE tran_date <= t.tran_date) total_unique_cust\n",
    "FROM cust_tran_fact t\n",
    "-- GROUP BY tran_date\n",
    "ORDER BY tran_date;\n",
    "\n",
    "\n",
    "\n",
    "-- 3. Total transaction amount per customer per day ( if its C then add if D then subtract )\n",
    "SELECT tran_date, cust_id, SUM(tran_ammt) total_tran_ammt\n",
    "FROM\n",
    "    (SELECT tran_date, cust_id, \n",
    "        CASE \n",
    "            WHEN tran_type = 'C'\n",
    "                THEN tran_ammount\n",
    "            ELSE -tran_ammount\n",
    "        END AS tran_ammt\n",
    "    FROM cust_tran_fact) t\n",
    "GROUP BY tran_date, cust_id\n",
    "\n",
    "\n",
    "\n",
    "-- 4. Find out duplicate transaction in total.\n",
    "SELECT tran_id, cust_id,  tran_date, tran_ammount, tran_type\n",
    "FROM cust_tran_fact tf\n",
    "GROUP BY tran_id, cust_id,  tran_date, tran_ammount, tran_type\n",
    "HAVING COUNT(*) > 1;\n",
    "\n",
    "\n",
    "\n",
    "-- 5. show the transaction which has debit but never credit before. (BROKEN FOR HIVE EMR) \n",
    "WITH counts AS(\n",
    "    SELECT tran_id, tran_type, tran_date,\n",
    "    -- count all 'C' type transactions with same id that happened before tran_date (if it is 0, there were no credits before the transaction) \n",
    "    (\n",
    "        SELECT COUNT(tran_id) FROM cust_tran_fact \n",
    "        WHERE tran_date <= tf.tran_date AND tran_id = tf.tran_id AND tran_type = 'C'\n",
    "    ) FROM cust_tran_fact tf)\n",
    "SELECT tran_id, tran_date FROM counts WHERE tran_type = 'D' AND count = 0;\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30cf0e1abb529a22bc607410d8585599c1f1527cc04e9da2f800037aa994db87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
