{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import db\n",
    "from utils import s3\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1.Create table :tran_fact\\ntran_id int, cust_id varchar(20),tran_ammount decimal(10,2), tran_type varchar(1), tran_country_cd varchar(3),tran_date date\\ntran_id : random id (ex : FX_123456,TD_224452  (Concat [FX/TD] with 6 digit number)\\ncust_id : cust_12345 (concat cust+ 4 digit number)\\ntran_ammount : $ ammount ( 3 dgit to 10 digit number)\\ntran_type : C/D (Random Value)\\ncountry_cd : ['USA','CAN','IND','AFG','CHN','JPN','KON','PAL']\\ntran_date : ['2022-01-01' to '2022-03-10' ]\\n\\nGenerate records for every day with the date range given [ each day generate 1000 to 10000 records]\\nhave 7 days fro now in tester\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "1.Create table :tran_fact\n",
    "tran_id int, cust_id varchar(20),tran_ammount decimal(10,2), tran_type varchar(1), tran_country_cd varchar(3),tran_date date\n",
    "tran_id : random id (ex : FX_123456,TD_224452  (Concat [FX/TD] with 6 digit number)\n",
    "cust_id : cust_12345 (concat cust+ 4 digit number)\n",
    "tran_ammount : $ ammount ( 3 dgit to 10 digit number)\n",
    "tran_type : C/D (Random Value)\n",
    "country_cd : ['USA','CAN','IND','AFG','CHN','JPN','KON','PAL']\n",
    "tran_date : ['2022-01-01' to '2022-03-10' ]\n",
    "\n",
    "Generate records for every day with the date range given [ each day generate 1000 to 10000 records]\n",
    "have 7 days fro now in tester\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "CREATE SCHEMA IF NOT EXISTS hadoop;\n",
    "DROP TABLE hadoop.tran_fact;\n",
    "CREATE TABLE IF NOT EXISTS hadoop.tran_fact(\n",
    "    tran_id varchar(18) encode raw, \n",
    "    cust_id varchar(20) encode raw,\n",
    "    tran_ammount decimal(10,2) encode AZ64, \n",
    "    tran_type varchar(1) encode raw, \n",
    "    tran_country_cd varchar(3) encode bytedict,\n",
    "    tran_date date encode delta32k\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# def generate_dummy_data(start: datetime, num_days : int, num_records : int ):\n",
    "    \n",
    "start_date = datetime.datetime(2022, 1, 1)\n",
    "num_days = 7\n",
    "num_records = 5000\n",
    "\n",
    "\n",
    "def generate_dummy_data(start: datetime, num_days : int, num_records : int, filepath = 'data/hadoop/'):\n",
    "    tran_country_cds = ['USA','CAN','IND','AFG','CHN','JPN','KON','PAL']\n",
    "    tran_types = ['C', 'D']\n",
    "    id_prefixes = ['FX', 'TD']\n",
    "    header = 'tran_id,cust_id,tran_ammount,tran_type,tran_country_cd,tran_date\\n'\n",
    "    files_created = []\n",
    "    for i in range(num_days):\n",
    "        tran_date = start_date + datetime.timedelta(days=i)\n",
    "        filename = tran_date.strftime(\"tran_fact_%Y-%m-%d\") + \".csv\"\n",
    "        f = open(filepath + filename, 'w')\n",
    "        f.write(header)\n",
    "        for j in range(num_records):\n",
    "            tran_ammount = round(random.uniform(100.00, 99999999.99),2)\n",
    "            tran_type = random.choice(tran_types)\n",
    "            tran_country_cd = random.choice(tran_country_cds)\n",
    "            tran_id = random.choice(id_prefixes) + '_' + tran_date.strftime(\"%Y%m%d\") + '_' +  f\"{j+1:06}\"\n",
    "            cust_id = 'cust_' + f\"{random.randint(1, 9999):04}\"\n",
    "            f.write(tran_id + \",\" + cust_id + \",\" + str(tran_ammount) + \",\"\n",
    "                + tran_type + \",\" + tran_country_cd + \",\" + tran_date.strftime(\"%Y-%m-%d\") + '\\n')\n",
    "        files_created.append((filename, filepath, tran_date.strftime('%Y-%m-%d')))\n",
    "        f.close()\n",
    "    return files_created\n",
    "        \n",
    "files_created = generate_dummy_data(start_date, num_days, num_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "2. Load each file into s3. [ each with folder as 2022-01-01,2022-01-02]\n",
    "'''\n",
    "for f in files_created:\n",
    "    s3.upload_file(f[1] + f[0], 'quintrix-spearscjs', 'cards_ingest/tran_fact/daily/' + f[2] + '/' + f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql/create/ct_hadoop_tran_fact.sql done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3.Create table in Redshift.\n",
    "'''\n",
    "query = 'CREATE SCHEMA IF NOT EXISTS hadoop'\n",
    "db.do_query(query, [])\n",
    "db.do_query_file('sql/create/ct_hadoop_tran_fact.sql',[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. Copy data to redshift  [append mode]\n",
    "'''\n",
    "db.copy('tran_fact', 'hadoop',  's3://quintrix-spearscjs/hadoop/data/daily/', db.redshift_iam, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Unload query sum(tran)amt by country cd to parquet file in s3.\n",
    "'''\n",
    "subquery = 'SELECT tran_country_cd, SUM(tran_ammount) FROM hadoop.tran_fact GROUP BY tran_country_cd;'\n",
    "bucket = 's3://quintrix-spearscjs/hadoop/data/country/tran_ammt_sum/'\n",
    "query = \"\"\" \n",
    "    UNLOAD (%s) -- query string\n",
    "    TO %s   -- s3 bucket_name\n",
    "    IAM_ROLE %s -- redshift iam role\n",
    "    PARALLEL ON\n",
    "    ALLOWOVERWRITE \n",
    "    FORMAT PARQUET\n",
    "\"\"\"\n",
    "db.do_query(query, [subquery, bucket, db.redshift_iam])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30cf0e1abb529a22bc607410d8585599c1f1527cc04e9da2f800037aa994db87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
